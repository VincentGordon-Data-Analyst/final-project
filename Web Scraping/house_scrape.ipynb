{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Splinter\n",
    "executable_path = {'executable_path':\"C:\\Program Files (x86)\\msedgedriver.exe\"}\n",
    "browser = Browser('edge', **executable_path)\n",
    "\n",
    "# Url for scraping\n",
    "url = \"https://www.royallepage.ca/en/search/homes/?search_str=Ontario%2C+ON%2C+CAN&csrfmiddlewaretoken=YrzRsRQ7hui5kwIngTSfFcjdmkY4uzkOpTtA8xAWppg2PQrYHUihHDD2uSNjEGZN&property_type=7%2C8%2C5&house_type=102%2C103%2C104&features=&listing_type=&lat=50.926163435000035&lng=-84.74492999999995&upper_lat=&upper_lng=&lower_lat=&lower_lng=&bypass=&radius=&zoom=&display_type=gallery-view&travel_time=&travel_time_min=30&travel_time_mode=drive&travel_time_congestion=&da_id=&segment_id=&tier2=False&tier2_proximity=0&address=Ontario&method=homes&address_type=province&city_name=&prov_code=ON&school_id=&min_price=0&max_price=3000000&min_leaseprice=0&max_leaseprice=5000%2B&beds=0&baths=0&transactionType=SALE&archive_status=All&archive_timespan=6&sfproperty_type%5B7%5D=7&sfproperty_type%5B8%5D=8&sfproperty_type%5B5%5D=5&sfhouse_type%5B102%5D=102&sfhouse_type%5B103%5D=103&sfhouse_type%5B104%5D=104&keyword=&sortby=\"\n",
    "\n",
    "browser.visit(url)\n",
    "html = browser.html\n",
    "\n",
    "soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering data from page: 1\n",
      "Gathering data from page: 2\n",
      "Gathering data from page: 3\n",
      "Gathering data from page: 4\n",
      "Gathering data from page: 5\n",
      "Gathering data from page: 6\n",
      "Gathering data from page: 7\n",
      "Gathering data from page: 8\n",
      "Gathering data from page: 9\n",
      "Gathering data from page: 10\n",
      "Gathering data from page: 11\n",
      "Gathering data from page: 12\n",
      "Gathering data from page: 13\n",
      "Gathering data from page: 14\n",
      "Gathering data from page: 15\n",
      "Gathering data from page: 16\n",
      "Gathering data from page: 17\n",
      "Gathering data from page: 18\n",
      "Gathering data from page: 19\n",
      "Gathering data from page: 20\n",
      "Gathering data from page: 21\n",
      "Gathering data from page: 22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1012"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through all pages to collect data\n",
    "house_listings = []\n",
    "for x in range(1, 23):\n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "    links = soup.find_all(class_='address-1')\n",
    "    \n",
    "    # Get all address listings for buying    \n",
    "    print('Gathering data from page:', x)\n",
    "    for link in links:\n",
    "        house_listings.append(link.a['href'])\n",
    "    browser.find_by_css('.next').click()\n",
    "\n",
    "# Number of listings\n",
    "len(house_listings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected data for: 33 SCUFFLER DR, Vaughan, Ontario, L6A 4Y7\n",
      "Collected data for: 11134 5 SIDE RD, Halton Hills, Ontario, L7G 4S6\n",
      "Collected data for: 14541 NIAGARA RIVER PKWY, Niagara-on-the-Lake, Ontario, L0S 1L0\n",
      "Collected data for: 15415 JANE ST, King, Ontario, L7B 1A3\n",
      "Collected data for: 31 WISPI SHORE RD, Kawartha Lakes, Ontario, K9V 0K4\n",
      "Collected data for: 4282 VIVIAN RD, Whitchurch-Stouffville, Ontario, L4A 1Z2\n",
      "Collected data for: 57 ALAMOSA DR, Toronto, Ontario, M2J 2N8\n",
      "Collected data for: 121 WATERVIEW COMMON, Oakville, Ontario, L6L 0E7\n",
      "Collected data for: 3696 FERRETTI CRT, Innisfil, Ontario, L9S 0N6\n",
      "Collected data for: 643 WEST OVAL Drive, Burlington, Ontario, L7T 1C1\n",
      "Collected data for: 40 DEAN PL, Vaughan, Ontario, L3L 0A8\n",
      "Collected data for: 48 FOOTHILLS CRES, Brampton, Ontario, L6P 4G9\n",
      "Collected data for: 13066 KEELE ST, King, Ontario, L7B 1H8\n",
      "Collected data for: 1041 BRANDYWINE COURT, Ottawa, Ontario, K4M 1J2\n",
      "Collected data for: 8254 21/22 NOTTAWASAGA SDRD, Clearview, Ontario, L0M 1H0\n",
      "Collected data for: 5 WHITELOCK CRES, Toronto, Ontario, M2K 1V9\n",
      "Collected data for: 1473 DURHAM ST, Oakville, Ontario, L6J 2P4\n",
      "Collected data for: 2 DONWOODS CRES, Whitby, Ontario, L1R 0K9\n",
      "Collected data for: 1588 CAROLYN RD, Mississauga, Ontario, L5M 2E1\n",
      "Collected data for: 34 MARNI LANE, Springwater, Ontario, L0L 2K0\n",
      "Collected data for: 24 LOVE CRT, Richmond Hill, Ontario, L4B 0G2\n",
      "Collected data for: 73 ACREDALE DR, Hamilton, Ontario, L0R 1H2\n",
      "Collected data for: 29 ROWE ST, Bradford West Gwillimbury, Ontario\n",
      "Collected data for: 338 BROADWAY AVE, Toronto, Ontario, M4P 1W7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\ClassWork\\git\\final-project\\Web Scraping\\house_scrape.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ClassWork/git/final-project/Web%20Scraping/house_scrape.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(house_listings)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ClassWork/git/final-project/Web%20Scraping/house_scrape.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     url \u001b[39m=\u001b[39m house_listings[i]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ClassWork/git/final-project/Web%20Scraping/house_scrape.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     browser\u001b[39m.\u001b[39;49mvisit(url)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ClassWork/git/final-project/Web%20Scraping/house_scrape.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     html \u001b[39m=\u001b[39m browser\u001b[39m.\u001b[39mhtml\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/ClassWork/git/final-project/Web%20Scraping/house_scrape.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     soup \u001b[39m=\u001b[39m bs(html, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\splinter\\driver\\webdriver\\__init__.py:319\u001b[0m, in \u001b[0;36mBaseWebDriver.visit\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit\u001b[39m(\u001b[39mself\u001b[39m, url):\n\u001b[1;32m--> 319\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdriver\u001b[39m.\u001b[39;49mget(url)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:333\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, url):\n\u001b[0;32m    330\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39m    Loads a web page in the current browser session.\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 333\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mGET, {\u001b[39m'\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m'\u001b[39;49m: url})\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:319\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    316\u001b[0m         params[\u001b[39m'\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_id\n\u001b[0;32m    318\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_value(params)\n\u001b[1;32m--> 319\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcommand_executor\u001b[39m.\u001b[39;49mexecute(driver_command, params)\n\u001b[0;32m    320\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[0;32m    321\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_handler\u001b[39m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:374\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    372\u001b[0m data \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mdump_json(params)\n\u001b[0;32m    373\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url, path)\n\u001b[1;32m--> 374\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(command_info[\u001b[39m0\u001b[39;49m], url, body\u001b[39m=\u001b[39;49mdata)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\splinter\\driver\\webdriver\\remote_connection.py:19\u001b[0m, in \u001b[0;36mpatch_request\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[0;32m     18\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m         \u001b[39mreturn\u001b[39;00m old_request(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     20\u001b[0m     \u001b[39mexcept\u001b[39;00m (socket\u001b[39m.\u001b[39merror, HTTPException, \u001b[39mIOError\u001b[39;00m, \u001b[39mOSError\u001b[39;00m, MaxRetryError) \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     21\u001b[0m         exception \u001b[39m=\u001b[39m exc\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:397\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    394\u001b[0m     body \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 397\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[0;32m    399\u001b[0m     statuscode \u001b[39m=\u001b[39m resp\u001b[39m.\u001b[39mstatus\n\u001b[0;32m    400\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\urllib3\\request.py:78\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_url(\n\u001b[0;32m     75\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[0;32m     76\u001b[0m     )\n\u001b[0;32m     77\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_body(\n\u001b[0;32m     79\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[0;32m     80\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\urllib3\\request.py:170\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    167\u001b[0m extra_kw[\u001b[39m\"\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mupdate(headers)\n\u001b[0;32m    168\u001b[0m extra_kw\u001b[39m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 170\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra_kw)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\urllib3\\poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    374\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, u\u001b[39m.\u001b[39mrequest_uri, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    378\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n\u001b[0;32m    379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[0;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[0;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\http\\client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1377\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1378\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   1379\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\http\\client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    321\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    322\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\http\\client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 281\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    282\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    283\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Import the API key\n",
    "from config import apiKey\n",
    "\n",
    "# Set up Splinter\n",
    "executable_path = {'executable_path':\"C:\\Program Files (x86)\\msedgedriver.exe\"}\n",
    "browser = Browser('edge', **executable_path)\n",
    "\n",
    "\n",
    "# Visit each listing and grab relevant data\n",
    "house_listing_info = []\n",
    "for i in range(len(house_listings)):\n",
    "    url = house_listings[i]\n",
    "    browser.visit(url)\n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "    houses = {} \n",
    "    \n",
    "    # Gather information on living space\n",
    "    living_space_section = soup.find('div', class_='property-meta-info')\n",
    "\n",
    "    # Get exact address\n",
    "    address = living_space_section.find('div', class_='title--h2 u-no-margins').text\n",
    "\n",
    "\n",
    "    # Get price\n",
    "    price = living_space_section.find('span', class_=\"title title--h1 price\").text.strip()\n",
    "\n",
    "    \n",
    "    # Get number of beds\n",
    "    bed_info = living_space_section.find('div', class_='bed-bath-box__item beds')\n",
    "    bed_count = bed_info.find('p', class_='bed-bath-box__value').text\n",
    "\n",
    "\n",
    "    # Get number of baths\n",
    "    bath_info = living_space_section.find('div', class_='bed-bath-box__item baths')\n",
    "    bath_count = bath_info.find('p', class_='bed-bath-box__value').text\n",
    "    \n",
    "    \n",
    "    # House features\n",
    "    building_feature_section = soup.find('div', class_=\"details-row\")\n",
    "    labels = building_feature_section.find_all('span', class_='label')\n",
    "    values = building_feature_section.find_all('span', class_=\"value\")\n",
    "    \n",
    "\n",
    "    style_type = values[0].text.strip(\":\")\n",
    "    # cooling_type = values[i].text.strip(\":\")\n",
    "    # heating_fuel = values[i].text.strip(\":\")\n",
    "    # heating_type = values[i].text.strip(\":\")\n",
    "    # fire_place = values[-4].text.strip(\":\")\n",
    "    \n",
    "    # Store in dictionary\n",
    "    houses['address'] = address\n",
    "    houses['price'] = price\n",
    "    houses['number_of_beds'] = bed_count\n",
    "    houses['number_of_baths'] = bath_count\n",
    "    houses['style'] = style_type\n",
    "    # houses['cooling_type'] = cooling_type\n",
    "    # houses['heating_fuel'] = heating_fuel\n",
    "    # houses['heating_type'] = heating_type\n",
    "    # houses['fire_place'] = fire_place\n",
    "    \n",
    "    # Build target url with address and apikey\n",
    "    string_search = address.split(\",\")[1:]\n",
    "    new_string = (\",\").join(string_search).strip()                           \n",
    "    \n",
    "    target_url = f\"https://api.geoapify.com/v1/geocode/search?text={new_string}&format=json&apiKey={apiKey}\"\n",
    "    \n",
    "    # Run a request to endpoint and convert result to json\n",
    "    geo_data = requests.get(target_url).json()\n",
    "\n",
    "    # Get coordinate information\n",
    "    lat = geo_data[\"results\"][0][\"lat\"]\n",
    "    lon = geo_data[\"results\"][0][\"lon\"]\n",
    "    \n",
    "    houses['lat'] = lat\n",
    "    houses['lon'] = lon\n",
    "        \n",
    "    print(f\"Collected data for: {address}\")\n",
    "    house_listing_info.append(houses)\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natural gas'"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wanted_features = ['Fireplace', 'Style', 'Heating Fuel']\n",
    "\n",
    "listed_features = []\n",
    "listed_values = []\n",
    "for i in range(len(labels)):\n",
    "    listed_features.append(labels[i].text.strip(\":\"))\n",
    "    listed_values.append(values[i].text.strip(\":\"))\n",
    "    \n",
    "for i in range(len(wanted_features)):\n",
    "    if wanted_features[i] in listed_features:\n",
    "        shared_index = listed_features.index(wanted_features[i])\n",
    "        value = listed_values[shared_index]\n",
    "value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected data for: 33 SCUFFLER DR, Vaughan, Ontario, L6A 4Y7\n",
      "Collected data for: 11134 5 SIDE RD, Halton Hills, Ontario, L7G 4S6\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Import the API key\n",
    "from config import apiKey\n",
    "\n",
    "# Set up Splinter\n",
    "executable_path = {'executable_path':\"C:\\Program Files (x86)\\msedgedriver.exe\"}\n",
    "browser = Browser('edge', **executable_path)\n",
    "\n",
    "\n",
    "# Visit each listing and grab relevant data\n",
    "house_listing_info = []\n",
    "for i in range(len(house_listings)):\n",
    "    url = house_listings[i]\n",
    "    browser.visit(url)\n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "    houses = {} \n",
    "    \n",
    "    # Gather information on living space\n",
    "    living_space_section = soup.find('div', class_='property-meta-info')\n",
    "\n",
    "    # Get exact address\n",
    "    address = living_space_section.find('div', class_='title--h2 u-no-margins').text\n",
    "\n",
    "\n",
    "    # Get price\n",
    "    price = living_space_section.find('span', class_=\"title title--h1 price\").text.strip()\n",
    "\n",
    "    \n",
    "    # Get number of beds\n",
    "    bed_info = living_space_section.find('div', class_='bed-bath-box__item beds')\n",
    "    bed_count = bed_info.find('p', class_='bed-bath-box__value').text\n",
    "\n",
    "\n",
    "    # Get number of baths\n",
    "    bath_info = living_space_section.find('div', class_='bed-bath-box__item baths')\n",
    "    bath_count = bath_info.find('p', class_='bed-bath-box__value').text\n",
    "    \n",
    "    \n",
    "    # House features\n",
    "    building_feature_section = soup.find('div', class_=\"details-row\")\n",
    "    labels = building_feature_section.find_all('span', class_='label')\n",
    "    values = building_feature_section.find_all('span', class_=\"value\")\n",
    "    \n",
    "    \n",
    "    wanted_features = ['Fireplace', 'Style', 'Heating Fuel', 'Cooling Type', 'Heating Type', 'Building Type']\n",
    "    \n",
    "    listed_features = []\n",
    "    listed_values = []\n",
    "    for i in range(len(labels)):\n",
    "        listed_features.append(labels[i].text.strip(\":\"))\n",
    "        listed_values.append(values[i].text.strip(\":\"))\n",
    "        \n",
    "    for i in range(len(wanted_features)):\n",
    "        if wanted_features[i] in listed_features:\n",
    "            shared_index = listed_features.index(wanted_features[i])\n",
    "            value = listed_values[shared_index]\n",
    "            \n",
    "                # Store in dictionary\n",
    "            houses['address'] = address\n",
    "            houses['price'] = price\n",
    "            houses['number_of_beds'] = bed_count\n",
    "            houses['number_of_baths'] = bath_count\n",
    "            houses['style'] = value\n",
    "            houses['building_type'] = value\n",
    "            houses['cooling_type'] = value\n",
    "            houses['heating_fuel'] = value\n",
    "            houses['heating_type'] = value\n",
    "            houses['fire_place'] = value\n",
    "        else:\n",
    "            value = \"\"\n",
    "    \n",
    "    # Build target url with address and apikey\n",
    "    string_search = address.split(\",\")[1:]\n",
    "    new_string = (\",\").join(string_search).strip()                           \n",
    "    \n",
    "    target_url = f\"https://api.geoapify.com/v1/geocode/search?text={new_string}&format=json&apiKey={apiKey}\"\n",
    "    \n",
    "    # Run a request to endpoint and convert result to json\n",
    "    geo_data = requests.get(target_url).json()\n",
    "\n",
    "    # Get coordinate information\n",
    "    lat = geo_data[\"results\"][0][\"lat\"]\n",
    "    lon = geo_data[\"results\"][0][\"lon\"]\n",
    "    \n",
    "    houses['lat'] = lat\n",
    "    houses['lon'] = lon\n",
    "        \n",
    "    print(f\"Collected data for: {address}\")\n",
    "    house_listing_info.append(houses)\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n",
      "Detached\n",
      "Central air conditioning\n",
      "Forced air\n",
      "House\n"
     ]
    }
   ],
   "source": [
    "wanted_features = ['Fireplace', 'Style', 'Heating Fuel', 'Cooling Type', 'Heating Type', 'Building Type']\n",
    "    \n",
    "listed_features = []\n",
    "listed_values = []\n",
    "for i in range(len(labels)):\n",
    "    listed_features.append(labels[i].text.strip(\":\"))\n",
    "    listed_values.append(values[i].text.strip(\":\"))\n",
    "    \n",
    "for i in range(len(wanted_features)):\n",
    "    if wanted_features[i] in listed_features:\n",
    "        shared_index = listed_features.index(wanted_features[i])\n",
    "        value = listed_values[shared_index]\n",
    "        print(value)\n",
    "    else:\n",
    "        style_type = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows of data to work with: 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Rows of data to work with: {len(house_listing_info)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "try:\n",
    "    with open('./Resources/housing.csv', 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=['address', 'price', 'number_of_beds', 'number_of_baths', 'style', 'cooling_type','heating_fuel', 'heating_type', 'fire_place', 'lat', 'lon'])\n",
    "        writer.writeheader()\n",
    "        for data in house_listing_info:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
